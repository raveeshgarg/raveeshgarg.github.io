# Raveesh Garg

![Profile Photo](photo.jpg) 

I am currently a PhD student in Electrical and Computer Engineering at [Georgia Institute of Technology](https://www.gatech.edu/). I joined Georgia Tech in Fall 2019 after completing my Bachelor of Engineering in Electronics and Instrumentation Engineering from [Birla Institute of Technology and Science, Pilani](https://www.bits-pilani.ac.in/).

My research focuses on Domain-Specific Accelerators and Mapping for AI, Graph, and HPC Applications. My general research interests include Computer Architecture, Programmable Spatial Accelerators, Domain-Specific Accelerators for AI/HPC, and On-chip Networks.

[Download my CV](Public_CV.pdf) 

## Experience

- **Research Intern** at IBM Research – TJ Watson Center, Yorktown Heights, NY, USA (May 2024 – Aug 2024)
- **Part-time Student Researcher** at Meta Reality Labs; Atlanta, GA, USA (Aug 2022 – Nov 2022)
- **Research Scientist Intern** at Meta Reality Labs; Sunnyvale, CA, USA (May 2022 – Aug 2022)

## Education

- **PhD in Electrical and Computer Engineering** at Georgia Institute of Technology
  - *Advisors*: Dr. Tushar Krishna and Dr. Michael Pellauer
  - *Duration*: 2021 to Present
  - *GPA*: 4/4

- **Master’s in Electrical and Computer Engineering** at Georgia Institute of Technology
  - *Advisors*: Dr. Tushar Krishna and Dr. Michael Pellauer
  - *Duration*: 2019 to 2021
  - *Master’s Thesis*: [Understanding the Design Space of Dataflows for Graph Neural Network Accelerators](https://smartech.gatech.edu/)
  - *GPA*: 4/4

- **Bachelor’s in Electronics and Instrumentation Engineering** at Birla Institute of Technology and Science, Pilani
  - *Duration*: 2015 to 2019
  - *GPA*: 9.29/10

## Selected Publications and Pre-prints

- **CELLO: Co-designing Schedule and Hybrid Implicit/Explicit Buffer for Complex Tensor Reuse**
  - *Authors*: Raveesh Garg, Michael Pellauer, Sivasankaran Rajamanickam, and Tushar Krishna
  - *Conference*: 39th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2025)
  - [ArXiv Link](https://arxiv.org/)

- **Flexagon: A Multi-Dataflow Sparse-Sparse Matrix Multiplication Accelerator for Efficient DNN Processing**
  - *Authors*: Francisco Muñoz-Martínez, Raveesh Garg, José L. Abellán, Michael Pellauer, Manuel E. Acacio, and Tushar Krishna
  - *Conference*: 28th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS 2023)
  - [Published Paper Link](https://dl.acm.org/) | [ArXiv Link](https://arxiv.org/)

- **Understanding the Design-Space of Sparse/Dense Multiphase GNN dataflows on Spatial Accelerators**
  - *Authors*: Raveesh Garg, Eric Qin, Francisco Muñoz-Martínez, Robert Guirado, Akshay Jain, Sergi Abadal, José L. Abellán, Manuel E. Acacio, Eduard Alarcón, Sivasankaran Rajamanickam, and Tushar Krishna
  - *Conference*: 36th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2022)
  - [Published Paper Link](https://ieeexplore.ieee.org/) | [ArXiv Link](https://arxiv.org/)
  - *Note*: Best Paper Nominee [Top 5 from 474 submissions]

For a complete list of publications, please visit my [Google Scholar profile](https://scholar.google.com/).

## Artifacts

- **OMEGA**: A simulation Framework for Observing Mapping Efficiency over GNN Accelerators
  - [GitHub Repository](https://github.com/)

## Workshops and Tutorials

- **Tutorial (Organizer and Presenter)** at ASPLOS 2023: Enabling Detailed Cycle-Level Simulation of AI and HPC Applications with Detailed Memory Hierarchy using STONNE, OMEGA, and SST-STONNE
  - [Website](https://stonne-simulator.github.io/)

- **Tutorial (Organizer and Presenter)** at ASPLOS 2022: STONNE+OMEGA: Cycle-level Simulation of Dense/Sparse DNN and GNN Accelerators
  - [Website](https://stonne-simulator.github.io/)

- **Young Architect Workshop (Author and Presenter)** at ASPLOS 2022: A Communication-Centric Dataflow Accelerator for High-Performance Conjugate Gradient.
  - [Lightning Talk](https://www.youtube.com/)

- **ModSim 2022 (Author and Presenter)**: SST-STONNE: Enabling cycle-level simulation of flexible spatial accelerators for DNNs and GNNs with a detailed memory hierarchy.

## Invited Talks

- **Minisymposium** “Co-Design of Data Flow Accelerators for Scientific Simulations and Machine Learning” at SIAM PP’22.
  - *Talk Title*: Understanding the Design Space of Sparse/Dense Multiphase Dataflows for Mapping Graph Neural Networks on Spatial Accelerators
  - [Abstract](https://example.com/)

## Awards and Honors

- **Best Paper Award Nominee** at IPDPS 2022
  - *Note*: Top 5 from 474 submissions

## Contact

- **Email**: raveesh.g@gatech.edu
- **LinkedIn**: [Profile](https://www.linkedin.com/)

